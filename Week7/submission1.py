
'''
Проект: предсказания победителя в онлайн-игре
'''

'''
Вам необходимо провести описанные в документе final-statement.html (или final-statement.ipynb) 
два этапа исследования (для двух подходов к решению задачи), 
написать по результатам каждого этапа небольшой отчет 
(ниже указаны вопросы, ответы на которые должны содержаться в отчете), 
и предоставить для ревью данный отчет и код, с помощью которого вы выполнили задание.

Не забывайте, что в выборке есть признаки, которые "заглядывают в будущее" — 
они помечены в описании данных как отсутствующие в тестовой выборке. 
Их прямое использование в модели приведет к переобучению, поэтому не забудьте исключить их из выборки.
'''

import pandas
import numpy as np

'''
Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. 
Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).
'''

features = pandas.read_csv('features.csv', index_col='match_id')

#print(features.head())

'''
Исключение последних 6 колонок
'duration',
'radiant_win',
'tower_status_radiant',
'tower_status_dire',
'barracks_status_radiant',
'barracks_status_dire']
'''
X_train = features.iloc[:, 0 : -6]

#print(X_train.head())

'''
Проверьте выборку на наличие пропусков с помощью функции count(), 
которая для каждого столбца показывает число заполненных значений. 
Много ли пропусков в данных? 
Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, 
почему их значения могут быть пропущены.
'''
def missing_value_of_data(data):
    total = data.isnull().sum().sort_values(ascending=False)
    percentage = round(total / data.shape[0] * 100, 2)
    return pandas.concat([total, percentage], axis=1, keys=['Total', 'Percentage'])

mis_val = missing_value_of_data(X_train)
#print(mis_val[mis_val.Total == 0])
#Пропуски данных из-за отсутвия набранной статистики определенных игроков

'''
Замените пропуски на нули с помощью функции fillna(). 
На самом деле этот способ является предпочтительным для логистической регрессии, 
поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание. 
Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение — 
в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. 
Также есть и другие подходы — например, замена пропуска на среднее значение признака. 
Мы не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой.
'''
X_train.fillna(0, inplace=True)

'''
Какой столбец содержит целевую переменную? 
Запишите его название.
'''
y_train = features.loc[:, 'radiant_win'] # целевая переменная в radiant_win

'''
Забудем, что в выборке есть категориальные признаки, 
и попробуем обучить градиентный бустинг над деревьями на имеющейся матрице "объекты-признаки". 
Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), 
не забудьте перемешать при этом выборку (shuffle=True), 
поскольку данные в таблице отсортированы по времени, 
и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества. 
Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации, 
попробуйте при этом разное количество деревьев 
(как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30). 
Долго ли настраивались классификаторы? 
Достигнут ли оптимум на испытанных значениях параметра n_estimators, 
или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?
'''
#Подход 1: градиентный бустинг "в лоб"

from sklearn.model_selection import KFold
gen = KFold(n_splits=5, shuffle=True)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
import datetime

res = {}
for i in [10, 20, 30]:
    GBC = GradientBoostingClassifier(n_estimators=i)
    if i == 30:
        start_time = datetime.datetime.now()
    quality = cross_val_score(GBC, X_train, y_train, cv=gen, scoring = 'roc_auc')
    if i == 30:
        end_time = datetime.datetime.now()
    res[i] = quality.mean()

print(res)
print(end_time - start_time)
#Время на крос-валидацию с грубиной 30 - 0:01:34.289747
#Качество при грубинах 10, 20 и 30 - {10: 0.6649154808361523, 20: 0.6827403409577955, 30: 0.6890790778024792}

'''
1. Какие признаки имеют пропуски среди своих значений? 
Что могут означать пропуски в этих признаках (ответьте на этот вопрос для двух любых признаков)?
---
Пропуски данных из-за отсутвия набранной статистики определенных игроков

2. Как называется столбец, содержащий целевую переменную?
---
Целевая переменная в radiant_win

3. Как долго проводилась кросс-валидация для градиентного бустинга с 30 деревьями? 
Инструкцию по измерению времени можно найти ниже по тексту. 
Какое качество при этом получилось? 
Напомним, что в данном задании мы используем метрику качества AUC-ROC.
---
Время на крос-валидацию с грубиной 30 - 0:01:34.289747
Качество при грубинах 10, 20 и 30 - {10: 0.6649154808361523, 20: 0.6827403409577955, 30: 0.6890790778024792}

4.Имеет ли смысл использовать больше 30 деревьев в градиентном бустинге? 
Что бы вы предложили делать, чтобы ускорить его обучение при увеличении количества деревьев?
---
Именение качества между глубиной 20 и 30 не значительная, увеличение более 30 не приведет к значительному росту качества,
однако значительно увеличит время для на проведения градиентного бустинга.

'''
#Подход 2: логистическая регрессия

from sklearn.model_selection import KFold
gen = KFold(n_splits=5, shuffle=True, random_state=241)

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV

scale = StandardScaler()
'''
X_train_scl = scale.fit_transform(X_train)

res = {}
for i in np.power(10.0, np.arange(-5,6)):
    LogR = LogisticRegression(penalty='l2', C=i)
    start_time = datetime.datetime.now()
    quality = cross_val_score(LogR, X_train_scl, y_train, cv=gen, scoring='roc_auc')
    end_time = datetime.datetime.now()
    res[i] = quality.mean()

#print(res)
print({x: y for x, y in filter(lambda x: res[x[0]] == max(res.values()), res.items())})
print(end_time - start_time)
'''
#Лучшее качество при логической регрессии, при С=0.01: 0.716341462186996
#Время на крос-валидацию при этом составило - 0:00:15.092872
'''
Среди признаков в выборке есть категориальные, которые мы использовали как числовые, 
что вряд ли является хорошей идеей. 
Категориальных признаков в этой задаче одиннадцать: 
lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero. 
Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. 
Изменилось ли качество? 
Чем вы можете это объяснить?
'''
'''
X_train = X_train.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',
                        'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)

X_train_scl = scale.fit_transform(X_train)

res = {}
for i in np.power(10.0, np.arange(-5,6)):
    LogR = LogisticRegression(penalty='l2', C=i)
    quality = cross_val_score(LogR, X_train_scl, y_train, cv=gen, scoring='roc_auc')
    res[i] = quality.mean()

#print(res)
print({x: y for x, y in filter(lambda x: res[x[0]] == max(res.values()), res.items())})
'''
#Лучшее значение логической регрессии при С=0.01: 0.7164009506527343

'''
На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают, 
какие именно герои играли за каждую команду. 
Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие. 
Выясните из данных, сколько различных идентификаторов героев существует в данной игре 
(вам может пригодиться фукнция unique или value_counts).
'''

def get_max_unique_no(data):
    res = pandas.Series()
    for i in range(1, 6):
        r = pandas.Series(data.loc[:, 'r%d_hero' % i].unique())
        d = pandas.Series(data.loc[:, 'd%d_hero' % i].unique())
        res = pandas.concat([res, r, d], ignore_index=True)
    return res.max()

#Всего различных идентификаторов - 108
#В выборке отсутсвуют номера 24, 107, 108 и 111
N = get_max_unique_no(X_train)

'''
Воспользуемся подходом "мешок слов" для кодирования информации о героях. 
Пусть всего в игре имеет N различных героев. 
Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче; единице, 
если i-й герой играл за команду Radiant; минус единице, если i-й герой играл за команду Dire. 
Ниже вы можете найти код, который выполняет данной преобразование. 
Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.
'''
def append_picks_players(data, N):
    X_pick = np.zeros((data.shape[0], N))

    for i, match_id in enumerate(data.index):
        for p in range(1, 6):
            X_pick[i, data.loc[match_id, 'r%d_hero' % p] - 1] = 1
            X_pick[i, data.loc[match_id, 'd%d_hero' % p] - 1] = -1

    for i in range(0, X_pick.shape[1]):
        mas = []
        for j in range(0, X_pick.shape[0]):
            mas.append(X_pick[j, i])
        data[i+1] = mas
    return data

X_train = append_picks_players(X_train, N)

X_train = X_train.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',
                        'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)

'''
Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. 
Какое получилось качество? 
Улучшилось ли оно? 
Чем вы можете это объяснить?
'''

X_train_scl = scale.fit_transform(X_train)

LogR = LogisticRegression(random_state=241)
grid = {'C': np.power(10.0, np.arange(-5, 6))}
gs = GridSearchCV(LogR, grid, scoring='roc_auc', cv=gen)
gs.fit(X_train_scl, y_train)

#Лучшее значение логической регрессии при С=0.01: 0.7519704890317176

'''
Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей 
(лучшей с точки зрения AUC-ROC на кросс-валидации). 
Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой 
(т.е. что модель не получилась константной).
'''

X_test = pandas.read_csv('features_test.csv', index_col='match_id')

X_test.fillna(0, inplace=True)

M = get_max_unique_no(X_test)
X_test = append_picks_players(X_test, M)

X_test = X_test.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',
                        'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis=1)

X_test_csl = scale.fit_transform(X_test)

X_test['radiant_win'] = gs.predict_proba(X_test_csl)[:, 1]

#print(X_test['radiant_win'].max())
#print(X_test['radiant_win'].min())
#Максимальное значение прогноза - 0.996328715925428
#Минимальное значение прогноза - 0.008705900769228427

X_test.iloc[:, -1].to_csv('result.csv', header=True, sep=',')

'''
1. Какое качество получилось у логистической регрессии над всеми исходными признаками? 
Как оно соотносится с качеством градиентного бустинга? 
Чем вы можете объяснить эту разницу? 
Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?
---
Лучшее качество при логической регрессии, при С=0.01: 0.716341462186996
Время на крос-валидацию при этом составило - 0:00:15.092872
Время на крос-валидацию с грубиной 30 при градиентном бустинге - 0:01:34.289747
Качество при грубинах 10, 20 и 30 - {10: 0.6649154808361523, 20: 0.6827403409577955, 30: 0.6890790778024792}

2. Как влияет на качество логистической регрессии удаление категориальных признаков 
(укажите новое значение метрики качества)? 
Чем вы можете объяснить это изменение?
---
Лучшее значение логической регрессии при С=0.01: 0.7164009506527343
Лучше, но на копейки.

3. Сколько различных идентификаторов героев существует в данной игре?
---
Всего различных идентификаторов - 108
В выборке отсутсвуют идентификаторы 24, 107, 108 и 111

4. Какое получилось качество при добавлении "мешка слов" по героям? 
Улучшилось ли оно по сравнению с предыдущим вариантом? 
Чем вы можете это объяснить?
---
Лучшее значение логической регрессии при С=0.01: 0.7519704890317176
Появились признаки с большей кореляцией с результатами матчей.

5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?
---
Максимальное значение прогноза - 0.996328715925428
Минимальное значение прогноза - 0.008705900769228427

'''

print('fin')